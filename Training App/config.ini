[Redshift_Credentials]
# redshift credentials
credentials =

[Redshift_Data]
# query to fetch data
query = 

[Data_Processing]
# outliers to be removed
outliers_to_be_removed = {'ccv_30_d': {'threshold': 700, 'is_above': True}}

# create buckets of categorical features
features_to_bucket = {'most_played_game': 25,
                     'country': 10,
                     'language': 10}
# columns to drop
cols_to_drop = ['channel_id', 'application_id', 'country', 'language', 'most_played_game']

# numeric features to convert to categorical
numeric_to_category = ['is_weekend_invite', 'is_tipping_panel', 'is_bot_command_usage',
                       'is_overlay', 'is_website_visit', 'is_se_live',
                       'is_alert_box_fired', 'is_sesp_page_visit', 'is_open_stream_report']

[Model_Parameters]
# Choose 1 of the 2 following types: CLASSIFIER or REGRESSOR
model_type = CLASSIFIER

# model parameters
param = {"objective": "binary:logistic",  # logistic regression for binary classification, output probability
         "seed": 42,  # used to generate the folds
         # "tree_method": "gpu_hist",  # speed up processing by using gpu power
         "early_stopping_rounds": 50,  # overfitting prevention, stop early if no improvement in learning
         "eval_metric": "aucpr",  # evaluation metric for validation data
         "n_estimators": 10000  # number of trees
         }

# number of tuning trials
n_trials = 2500

[Scoring_Functions]
# Choose 1 of the 3 following regression scoring functions: ['AveragePrecisionScore', 'LogLoss', 'RMSE']
regressor_scoring_functions = ['AveragePrecisionScore', 'LogLoss', 'RMSE']

# Choose 1 of the 4 following classification scoring functions: ['AveragePrecisionScore', 'F1Score', 'RecallScore', 'PrecisionScore']
classifier_scoring_functions = ['AveragePrecisionScore']

# filters
r2_filter = 0
precision_filter = 0.1


[GCS]
# ID of GCS bucket
bucket_name = acceptance-rate-prediction-streamelements-1337
